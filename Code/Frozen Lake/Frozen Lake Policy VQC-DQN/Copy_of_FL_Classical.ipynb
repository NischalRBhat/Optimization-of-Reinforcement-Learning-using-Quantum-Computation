{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "x19dKq8EbzWb",
        "execution": {
          "iopub.status.busy": "2023-11-13T09:04:02.826407Z",
          "iopub.execute_input": "2023-11-13T09:04:02.826937Z",
          "iopub.status.idle": "2023-11-13T09:04:02.834796Z",
          "shell.execute_reply.started": "2023-11-13T09:04:02.826894Z",
          "shell.execute_reply": "2023-11-13T09:04:02.833677Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"%%bash\n",
        "pip3 install pennylane==0.28.0\"\"\""
      ],
      "metadata": {
        "id": "lcjnV3aV1eZ8",
        "outputId": "fb82cce1-a1ad-47b3-d5fe-27dda42852eb",
        "execution": {
          "iopub.status.busy": "2023-11-13T09:04:02.837430Z",
          "iopub.execute_input": "2023-11-13T09:04:02.838305Z",
          "iopub.status.idle": "2023-11-13T09:04:16.452652Z",
          "shell.execute_reply.started": "2023-11-13T09:04:02.838266Z",
          "shell.execute_reply": "2023-11-13T09:04:16.451076Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'%%bash\\npip3 install pennylane==0.28.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"%%bash\n",
        "pip3 install gymnasium\"\"\""
      ],
      "metadata": {
        "id": "xXiT9yhtbzWg",
        "outputId": "7d9465fc-f4a4-492d-c52e-a8c9bc56ba4e",
        "execution": {
          "iopub.status.busy": "2023-11-13T09:04:16.454197Z",
          "iopub.execute_input": "2023-11-13T09:04:16.454573Z",
          "iopub.status.idle": "2023-11-13T09:04:16.462696Z",
          "shell.execute_reply.started": "2023-11-13T09:04:16.454538Z",
          "shell.execute_reply": "2023-11-13T09:04:16.461193Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'%%bash\\npip3 install gymnasium'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import math\n",
        "import random\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple, deque\n",
        "from itertools import count\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import gym.spaces\n",
        "from gym.envs.registration import register\n",
        "from gym.envs import toy_text\n",
        "\n",
        "class ShortestPathFrozenLake(toy_text.frozen_lake.FrozenLakeEnv):\n",
        "\tdef __init__(self, **kwargs):\n",
        "\t\tsuper(ShortestPathFrozenLake, self).__init__(**kwargs)\n",
        "\n",
        "\t\tself.nS = self.nrow * self.ncol\n",
        "\t\tself.nA = 4\n",
        "\t\tfor state in range(self.nS): # for all states\n",
        "\t\t\tfor action in range(self.nA): # for all actions\n",
        "\t\t\t\tmy_transitions = []\n",
        "\t\t\t\tfor (prob, next_state, _, is_terminal) in self.P[state][action]:\n",
        "\t\t\t\t\trow = next_state // self.ncol\n",
        "\t\t\t\t\tcol = next_state - row * self.ncol\n",
        "\t\t\t\t\ttile_type = self.desc[row, col]\n",
        "\t\t\t\t\tif tile_type == b'H':\n",
        "\t\t\t\t\t\treward = -1.0\n",
        "\t\t\t\t\telif tile_type == b'G':\n",
        "\t\t\t\t\t\treward = 10.\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\treward = -0.05\n",
        "\n",
        "\t\t\t\t\tmy_transitions.append((prob, next_state, reward, is_terminal))\n",
        "\t\t\t\tself.P[state][action] = my_transitions\n",
        "\n",
        "\n",
        "class BinaryWrapper(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super(BinaryWrapper, self).__init__(env)\n",
        "        self.bits = int(np.ceil(np.log2(env.observation_space.n)))\n",
        "        self.observation_space = gym.spaces.MultiBinary(self.bits)\n",
        "\n",
        "    def observation(self, obs):\n",
        "        binary = map(float, \"{0:b}\".format(int(obs)).zfill(self.bits))\n",
        "        return np.array(list(binary))\n",
        "\n",
        "# class FL(gym.ObservationWrapper):\n",
        "#     def __init__(self, env):\n",
        "#         super().__init__(env)\n",
        "#         self.observation_space = gym.spaces.MultiBinary(16)\n",
        "\n",
        "#     def observation(self, obs):\n",
        "#         obsi = np.zeros(16)\n",
        "#         obsi[obs] = 1\n",
        "#         return obsi\n",
        "\n",
        "\n",
        "register(\n",
        "        id='FrozenLake-VA', # name given to this new environment\n",
        "        entry_point=__name__ + ':ShortestPathFrozenLake', # env entry point\n",
        "        kwargs={'map_name': '4x4', 'is_slippery': False} # argument passed to the env\n",
        ")\n",
        "env = gym.make('FrozenLake-VA')\n",
        "env = BinaryWrapper(env)\n",
        "\n",
        "\n",
        "# set up matplotlib\n",
        "is_ipython = 'inline' in matplotlib.get_backend()\n",
        "if is_ipython:\n",
        "    from IPython import display\n",
        "\n",
        "plt.ion()\n",
        "\n",
        "# if GPU is to be used\n",
        "device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "9pqspmy0bzWh",
        "execution": {
          "iopub.status.busy": "2023-11-13T09:04:16.466390Z",
          "iopub.execute_input": "2023-11-13T09:04:16.466884Z",
          "iopub.status.idle": "2023-11-13T09:04:16.480340Z",
          "shell.execute_reply.started": "2023-11-13T09:04:16.466837Z",
          "shell.execute_reply": "2023-11-13T09:04:16.478875Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cdc06f3-9bf3-4d62-f001-fe9df7327f15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:542: UserWarning: \u001b[33mWARN: Overriding environment FrozenLake-VA\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {spec.id}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Transition = namedtuple('Transition',\n",
        "                        ('state', 'action', 'next_state', 'reward'))\n",
        "\n",
        "\n",
        "class ReplayMemory(object):\n",
        "\n",
        "    def __init__(self, capacity):\n",
        "        self.memory = deque([], maxlen=capacity)\n",
        "\n",
        "    def push(self, *args):\n",
        "        \"\"\"Save a transition\"\"\"\n",
        "        self.memory.append(Transition(*args))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ],
      "metadata": {
        "id": "M04d2DjhbzWh",
        "execution": {
          "iopub.status.busy": "2023-11-13T09:04:16.482469Z",
          "iopub.execute_input": "2023-11-13T09:04:16.483000Z",
          "iopub.status.idle": "2023-11-13T09:04:16.494730Z",
          "shell.execute_reply.started": "2023-11-13T09:04:16.482954Z",
          "shell.execute_reply": "2023-11-13T09:04:16.493287Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DQN(nn.Module):\n",
        "\n",
        "    def __init__(self, n_observations, n_actions):\n",
        "        super(DQN, self).__init__()\n",
        "        self.layer1 = nn.Linear(n_observations, 128)\n",
        "        self.layer2 = nn.Linear(128, 128)\n",
        "        self.layer3 = nn.Linear(128, n_actions)\n",
        "\n",
        "    # Called with either one element to determine next action, or a batch\n",
        "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.layer1(x))\n",
        "        x = F.relu(self.layer2(x))\n",
        "        return self.layer3(x)"
      ],
      "metadata": {
        "id": "x0sDllYAbzWi",
        "execution": {
          "iopub.status.busy": "2023-11-13T09:04:16.496340Z",
          "iopub.execute_input": "2023-11-13T09:04:16.497775Z",
          "iopub.status.idle": "2023-11-13T09:04:16.519302Z",
          "shell.execute_reply.started": "2023-11-13T09:04:16.497721Z",
          "shell.execute_reply": "2023-11-13T09:04:16.517572Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BATCH_SIZE is the number of transitions sampled from the replay buffer\n",
        "# GAMMA is the discount factor as mentioned in the previous section\n",
        "# EPS_START is the starting value of epsilon\n",
        "# EPS_END is the final value of epsilon\n",
        "# EPS_DECAY controls the rate of exponential decay of epsilon, higher means a slower decay\n",
        "# TAU is the update rate of the target network\n",
        "# LR is the learning rate of the ``AdamW`` optimizer\n",
        "BATCH_SIZE = 100\n",
        "GAMMA = 0.99\n",
        "EPS_START = 1.\n",
        "EPS_END = 0.001\n",
        "EPS_DECAY = 0.99\n",
        "TAU = 0.01\n",
        "LR = 1e-3\n",
        "\n",
        "\n",
        "# Get number of actions from gym action space\n",
        "n_actions = env.action_space.n\n",
        "# Get the number of state observations\n",
        "state = env.reset()\n",
        "n_observations = len(state)\n",
        "\n",
        "\n",
        "policy_net = DQN(4, 4).to(device)\n",
        "target_net = DQN(4, 4).to(device)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "optimizer = optim.RMSprop(policy_net.parameters(), lr=LR)\n",
        "memory = ReplayMemory(10000)\n",
        "\n",
        "\n",
        "steps_done = 0\n",
        "\n",
        "\n",
        "def select_action(state):\n",
        "    global steps_done\n",
        "    sample = random.random()\n",
        "    \"\"\"eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
        "        math.exp(-1. * steps_done / EPS_DECAY)\"\"\"\n",
        "    eps_threshold = max(\n",
        "            EPS_END, EPS_END +\n",
        "            (EPS_START - EPS_END) *\n",
        "            EPS_DECAY**steps_done)\n",
        "    steps_done += 1\n",
        "    if sample > eps_threshold:\n",
        "        with torch.no_grad():\n",
        "            # t.max(1) will return the largest column value of each row.\n",
        "            # second column on max result is index of where max element was\n",
        "            # found, so we pick action with the larger expected reward.\n",
        "            return policy_net(state).max(1)[1].view(1, 1)\n",
        "    else:\n",
        "        return torch.tensor([[env.action_space.sample()]], device=device, dtype=torch.long)\n",
        "\n",
        "\n",
        "episode_rewards = []\n",
        "\n",
        "\n",
        "def plot_durations(show_result=False):\n",
        "    plt.figure(1)\n",
        "    rewards_t = torch.tensor(episode_rewards, dtype=torch.float)\n",
        "    if show_result:\n",
        "        plt.title('Result')\n",
        "    else:\n",
        "        plt.clf()\n",
        "        plt.title('Training...')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Duration')\n",
        "    plt.plot(rewards_t.numpy())\n",
        "    # Take 100 episode averages and plot them too\n",
        "    if len(rewards_t) >= 10:\n",
        "        means = rewards_t.unfold(0, 10, 1).mean(1).view(-1)\n",
        "        means = torch.cat((torch.zeros(9), means))\n",
        "        plt.plot(means.numpy())\n",
        "\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "    if is_ipython:\n",
        "        if not show_result:\n",
        "            display.display(plt.gcf())\n",
        "            display.clear_output(wait=True)\n",
        "        else:\n",
        "            display.display(plt.gcf())"
      ],
      "metadata": {
        "id": "P1i4BzvlbzWj",
        "execution": {
          "iopub.status.busy": "2023-11-13T09:04:16.521330Z",
          "iopub.execute_input": "2023-11-13T09:04:16.521785Z",
          "iopub.status.idle": "2023-11-13T09:04:16.565571Z",
          "shell.execute_reply.started": "2023-11-13T09:04:16.521747Z",
          "shell.execute_reply": "2023-11-13T09:04:16.564089Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_model():\n",
        "    #print(1)\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return\n",
        "    transitions = memory.sample(BATCH_SIZE)\n",
        "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
        "    # detailed explanation). This converts batch-array of Transitions\n",
        "    # to Transition of batch-arrays.\n",
        "    batch = Transition(*zip(*transitions))\n",
        "\n",
        "    # Compute a mask of non-final states and concatenate the batch elements\n",
        "    # (a final state would've been the one after which simulation ended)\n",
        "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
        "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
        "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
        "                                                if s is not None])\n",
        "    state_batch = torch.cat(batch.state)\n",
        "    action_batch = torch.cat(batch.action)\n",
        "    reward_batch = torch.cat(batch.reward)\n",
        "\n",
        "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
        "    # columns of actions taken. These are the actions which would've been taken\n",
        "    # for each batch state according to policy_net\n",
        "    #print(2)\n",
        "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
        "    #print(3)\n",
        "    # Compute V(s_{t+1}) for all next states.\n",
        "    # Expected values of actions for non_final_next_states are computed based\n",
        "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
        "    # This is merged based on the mask, such that we'll have either the expected\n",
        "    # state value or 0 in case the state was final.\n",
        "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
        "    with torch.no_grad():\n",
        "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0]\n",
        "    # Compute the expected Q values\n",
        "    #print(4)\n",
        "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
        "    #print(5)\n",
        "\n",
        "    # Compute Huber loss\n",
        "    criterion = nn.SmoothL1Loss()\n",
        "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
        "    #print(6)\n",
        "\n",
        "    # Optimize the model\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    #print(7)\n",
        "    # In-place gradient clipping\n",
        "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 10)\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "obe9akLsbzWk",
        "execution": {
          "iopub.status.busy": "2023-11-13T09:04:16.569037Z",
          "iopub.execute_input": "2023-11-13T09:04:16.569537Z",
          "iopub.status.idle": "2023-11-13T09:04:16.584473Z",
          "shell.execute_reply.started": "2023-11-13T09:04:16.569490Z",
          "shell.execute_reply": "2023-11-13T09:04:16.582949Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_episodes = 1000\n",
        "\n",
        "for i_episode in range(num_episodes):\n",
        "    # Initialize the environment and get it's state\n",
        "    state = env.reset()\n",
        "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "    tot_rewards = 0\n",
        "    steps = 0\n",
        "    done = False\n",
        "    while not done:\n",
        "        action = select_action(state)\n",
        "        steps += 1\n",
        "        observation, reward, terminated, _ = env.step(action.item())\n",
        "        reward = torch.tensor([reward], device=device)\n",
        "        tot_rewards += reward\n",
        "        done = terminated\n",
        "\n",
        "        if done:\n",
        "            next_state = None\n",
        "        else:\n",
        "            next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "\n",
        "        # Store the transition in memory\n",
        "        memory.push(state, action, next_state, reward)\n",
        "\n",
        "        # Move to the next state\n",
        "        state = next_state\n",
        "\n",
        "        # Perform one step of the optimization (on the policy network)\n",
        "        if steps % 10 == 0:\n",
        "            optimize_model()\n",
        "\n",
        "        # Soft update of the target network's weights\n",
        "        # θ′ ← τ θ + (1 −τ )θ′\n",
        "        target_net_state_dict = target_net.state_dict()\n",
        "        policy_net_state_dict = policy_net.state_dict()\n",
        "        for key in policy_net_state_dict:\n",
        "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
        "        target_net.load_state_dict(target_net_state_dict)\n",
        "\n",
        "        if done:\n",
        "            episode_rewards.append(tot_rewards)\n",
        "            print(f\"Episode {i_episode} : {tot_rewards}\")\n",
        "            plot_durations()\n",
        "            break\n",
        "    #print(f\"Episode {i_episode}, Rewards : {tot_rewards}\")\n",
        "\n",
        "print('Complete')\n",
        "plot_durations(show_result=True)\n",
        "plt.ioff()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8fQ8e-v9bzWl",
        "outputId": "59eda76f-8f4d-4c16-d830-5270e808dd16",
        "execution": {
          "iopub.status.busy": "2023-11-13T09:04:16.588674Z",
          "iopub.execute_input": "2023-11-13T09:04:16.589370Z",
          "iopub.status.idle": "2023-11-13T11:08:29.387511Z",
          "shell.execute_reply.started": "2023-11-13T09:04:16.589315Z",
          "shell.execute_reply": "2023-11-13T11:08:29.386218Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complete\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_env = gym.make(\"FrozenLake-v1\", render_mode=\"rgb_array\", is_slippery = False)\n",
        "new_env = FL(new_env)"
      ],
      "metadata": {
        "id": "zHRxI801eqCN",
        "execution": {
          "iopub.status.busy": "2023-11-13T11:08:29.389633Z",
          "iopub.execute_input": "2023-11-13T11:08:29.390771Z",
          "iopub.status.idle": "2023-11-13T11:08:29.398737Z",
          "shell.execute_reply.started": "2023-11-13T11:08:29.390725Z",
          "shell.execute_reply": "2023-11-13T11:08:29.397223Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "for i_episode in range(10):\n",
        "    # Initialize the environment and get it's state\n",
        "    state = new_env.reset()\n",
        "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "    test_rewards = 0\n",
        "    done = False\n",
        "    steps = 0\n",
        "    while not done:\n",
        "        action = select_action(state)\n",
        "        steps += 1\n",
        "        observation, reward, terminated, _ = new_env.step(action.item())\n",
        "        reward = torch.tensor([reward], device=device)\n",
        "        test_rewards += reward\n",
        "        done = terminated\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "        else:\n",
        "            next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "\n",
        "        state = next_state\n",
        "\n",
        "    print(f\"Episode : {i_episode}, Reward = {test_rewards}, Steps = {steps}\")\n",
        "\n",
        "\n",
        "new_env.close()\n"
      ],
      "metadata": {
        "id": "UFE7mEWveBVj",
        "execution": {
          "iopub.status.busy": "2023-11-13T11:08:29.400567Z",
          "iopub.execute_input": "2023-11-13T11:08:29.401015Z",
          "iopub.status.idle": "2023-11-13T11:09:08.019934Z",
          "shell.execute_reply.started": "2023-11-13T11:08:29.400977Z",
          "shell.execute_reply": "2023-11-13T11:09:08.018780Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbabf07f-8d55-47b4-fcf7-ba85b5d951cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode : 0, Reward = tensor([1.]), Steps = 6\n",
            "Episode : 1, Reward = tensor([1.]), Steps = 6\n",
            "Episode : 2, Reward = tensor([1.]), Steps = 6\n",
            "Episode : 3, Reward = tensor([1.]), Steps = 6\n",
            "Episode : 4, Reward = tensor([1.]), Steps = 6\n",
            "Episode : 5, Reward = tensor([1.]), Steps = 6\n",
            "Episode : 6, Reward = tensor([1.]), Steps = 6\n",
            "Episode : 7, Reward = tensor([1.]), Steps = 6\n",
            "Episode : 8, Reward = tensor([1.]), Steps = 6\n",
            "Episode : 9, Reward = tensor([1.]), Steps = 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(policy_net.state_dict(), 'p_state_dict.pt')\n",
        "torch.save(target_net.state_dict(), 't_state_dict.pt')\n",
        "\n",
        "\"\"\"import pickle\n",
        "\n",
        "file = open('agents3', 'wb')\n",
        "arr = [trainer.exploration_decay, trainer.exploration_initial_eps, trainer.exploration_final_eps]\n",
        "\"\"\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-13T11:10:51.055262Z",
          "iopub.execute_input": "2023-11-13T11:10:51.056665Z",
          "iopub.status.idle": "2023-11-13T11:10:51.068807Z",
          "shell.execute_reply.started": "2023-11-13T11:10:51.056606Z",
          "shell.execute_reply": "2023-11-13T11:10:51.067185Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MaLnyd6mH5Fk",
        "outputId": "8c4dca65-d7d3-445e-f57e-3e9d094dac17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"import pickle\\n\\nfile = open('agents3', 'wb')\\narr = [trainer.exploration_decay, trainer.exploration_initial_eps, trainer.exploration_final_eps]\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}